<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Cooked Ahh Audio Effect</title>
<style>
body {
    font-family: Arial, sans-serif;
    background: #111;
    color: #eee;
    text-align: center;
    padding: 40px;
}
button, input {
    margin: 10px;
    padding: 10px 15px;
    font-size: 16px;
}
#progressContainer {
    width: 80%;
    height: 20px;
    background: #333;
    margin: 20px auto;
    border-radius: 10px;
    overflow: hidden;
}
#progressBar {
    width: 0%;
    height: 100%;
    background: #e33;
    transition: width 0.1s linear;
}
</style>
</head>
<body>

<h1>Alastor Voice Effect</h1>

<input type="file" id="fileInput" accept=".mp3,.wav,audio/*">
<br>
<button id="recordBtn">Record Audio</button>
<button id="stopRecordBtn" disabled>Stop Recording</button>
<br>
<button id="playBtn" disabled>Play with Effect</button>
<button id="stopBtn" disabled>Stop Playback</button>
<br>
<div id="progressContainer">
    <div id="progressBar"></div>
</div>
<br>
<a id="downloadLink" style="display:none">Download processed audio</a>

<script>
let audioContext = new (window.AudioContext || window.webkitAudioContext)();
let audioBuffer = null;
let sourceNode = null;
let isPlaying = false;

// Recording variables
let mediaRecorder = null;
let recordedChunks = [];

const fileInput = document.getElementById('fileInput');
const recordBtn = document.getElementById('recordBtn');
const stopRecordBtn = document.getElementById('stopRecordBtn');
const playBtn = document.getElementById('playBtn');
const stopBtn = document.getElementById('stopBtn');
const progressBar = document.getElementById('progressBar');
const downloadLink = document.getElementById('downloadLink');

// --- Upload MP3/WAV ---
fileInput.onchange = async e => {
    const file = e.target.files[0];
    if (!file) return;
    if (!file.type.startsWith('audio/') && !file.name.match(/\.(mp3|wav)$/i)) {
        alert('Please upload an audio file (MP3 or WAV).');
        return;
    }
    const arrayBuffer = await file.arrayBuffer();
    audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
    playBtn.disabled = false;
};

// --- Record Audio ---
recordBtn.onclick = async () => {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    mediaRecorder = new MediaRecorder(stream);
    recordedChunks = [];

    mediaRecorder.ondataavailable = e => recordedChunks.push(e.data);

    mediaRecorder.onstop = async () => {
        const blob = new Blob(recordedChunks, { type: 'audio/wav' });
        const arrayBuffer = await blob.arrayBuffer();
        audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
        playBtn.disabled = false;
        stopRecordBtn.disabled = true;
    };

    mediaRecorder.start();
    recordBtn.disabled = true;
    stopRecordBtn.disabled = false;
};

stopRecordBtn.onclick = () => {
    if (mediaRecorder) mediaRecorder.stop();
    recordBtn.disabled = false;
};

// --- Play with effect ---
playBtn.onclick = () => {
    if (!audioBuffer || isPlaying) return;

    sourceNode = audioContext.createBufferSource();
    sourceNode.buffer = audioBuffer;
    sourceNode.playbackRate.value = 1.15; // slight pitch up

    const chain = createEffectChain(audioContext);
    sourceNode.connect(chain.input);

    sourceNode.start();
    isPlaying = true;
    playBtn.disabled = true;
    stopBtn.disabled = false;

    const startTime = audioContext.currentTime;
    const duration = audioBuffer.duration;

    function updateProgress() {
        if (!isPlaying) return;
        const elapsed = audioContext.currentTime - startTime;
        progressBar.style.width = Math.min(100, (elapsed / duration) * 100) + '%';
        if (elapsed < duration) requestAnimationFrame(updateProgress);
        else stopPlayback();
    }
    requestAnimationFrame(updateProgress);

    // prepare download (raw audio)
    downloadLink.href = bufferToWavBlob(audioBuffer);
    downloadLink.download = "processed_voice.wav";
    downloadLink.style.display = "inline";
    downloadLink.textContent = "Download processed audio";
};

// --- Stop playback ---
stopBtn.onclick = stopPlayback;

function stopPlayback() {
    if (sourceNode) {
        sourceNode.stop();
        sourceNode.disconnect();
    }
    isPlaying = false;
    playBtn.disabled = false;
    stopBtn.disabled = true;
    progressBar.style.width = '0%';
}

// --- Effect chain ---
function createEffectChain(context) {
    // 1. Band-pass filter
    const bandpass = context.createBiquadFilter();
    bandpass.type = "bandpass";
    bandpass.frequency.value = 1600;
    bandpass.Q.value = 1.5;

    // 2. Distortion
    const distortion = context.createWaveShaper();
    distortion.curve = makeDistortionCurve(350);
    distortion.oversample = '4x';

    // 3. Subtle rhythmic reverb
    const convolver = context.createConvolver();
    convolver.buffer = createRhythmicReverb(context, 0.3, 2, 0.5);

    const gain = context.createGain();
    gain.gain.value = 0.8;

    bandpass.connect(distortion);
    distortion.connect(convolver);
    convolver.connect(gain);
    gain.connect(context.destination);

    return { input: bandpass, output: gain };
}

// --- Helpers ---
function makeDistortionCurve(amount) {
    const samples = 44100;
    const curve = new Float32Array(samples);
    const deg = Math.PI / 180;
    for (let i = 0; i < samples; i++) {
        const x = i * 2 / samples - 1;
        curve[i] = (3 + amount) * x * 20 * deg / (Math.PI + amount * Math.abs(x));
    }
    return curve;
}

// Subtle rhythmic reverb using short impulse with rhythmic decay
function createRhythmicReverb(ctx, duration, decay, pulseInterval) {
    const length = ctx.sampleRate * duration;
    const impulse = ctx.createBuffer(2, length, ctx.sampleRate);

    for (let ch = 0; ch < 2; ch++) {
        const data = impulse.getChannelData(ch);
        for (let i = 0; i < length; i++) {
            // Apply decay and rhythmic pulses
            const pulse = Math.sin((i / ctx.sampleRate) * (2 * Math.PI / pulseInterval)) * 0.1;
            data[i] = ((Math.random() * 2 - 1) * Math.pow(1 - i / length, decay)) * (0.5 + pulse);
        }
    }
    return impulse;
}

// Convert AudioBuffer to WAV Blob
function bufferToWavBlob(buffer) {
    const numOfChan = buffer.numberOfChannels;
    const length = buffer.length * numOfChan * 2 + 44;
    const view = new DataView(new ArrayBuffer(length));
    writeString(view, 0, "RIFF");
    view.setUint32(4, 36 + buffer.length * numOfChan * 2, true);
    writeString(view, 8, "WAVE");
    writeString(view, 12, "fmt ");
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, numOfChan, true);
    view.setUint32(24, buffer.sampleRate, true);
    view.setUint32(28, buffer.sampleRate * numOfChan * 2, true);
    view.setUint16(32, numOfChan * 2, true);
    view.setUint16(34, 16, true);
    writeString(view, 36, "data");
    view.setUint32(40, buffer.length * numOfChan * 2, true);

    let offset = 44;
    for (let i = 0; i < buffer.length; i++) {
        for (let ch = 0; ch < numOfChan; ch++) {
            let sample = buffer.getChannelData(ch)[i];
            sample = Math.max(-1, Math.min(1, sample));
            view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
            offset += 2;
        }
    }
    return new Blob([view], {type: "audio/wav"});
}

function writeString(view, offset, string) {
    for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
    }
}
</script>

</body>
</html>
